name: CI/CD

on:
  push:
    branches:
      - main  # Trigger the workflow on push to the main branch
  workflow_dispatch:  # Allow manual trigger from GitHub Actions UI

jobs:
  Create_Dataset_and_Run_DVC_Pipeline:
    runs-on: ubuntu-latest  # Use the latest Ubuntu runner for the workflow

    steps:
      # Checkout the code from GitHub repository
      - name: Checkout code
        uses: actions/checkout@v2  # Pulls the code from the repository

      # Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v2  # Sets up Python for the workflow
        with:
          python-version: '3.9'  # Specifies the Python version to use

      # Install dependencies from requirements.txt
      - name: Install dependencies
        run: |
          echo "Installing libraries ..."  
          pip install -r requirements.txt  

      - name: Create .env file dynamically
        run: |
          echo "Creating .env file..."

          echo "DAGSHUB_PASSWORD=${{ secrets.DAGSHUB_PASSWORD }}" >> .env
          echo "DAGSHUB_USER_NAME=${{ secrets.DAGSHUB_USER_NAME }}" >> .env
          echo "EVIDENTLY_PROJECT_ID=${{ secrets.EVIDENTLY_PROJECT_ID }}" >> .env
          echo "EVIDENTLY_TOKEN=${{ secrets.EVIDENTLY_TOKEN }}" >> .env
          echo "KAGGLE_KEY=${{ secrets.KAGGLE_KEY }}" >> .env
          echo "KAGGLE_USERNAME=${{ secrets.KAGGLE_USERNAME }}" >> .env
          echo "MLFLOW_TRACKING_URI=${{ secrets.MLFLOW_TRACKING_URI }}" >> .env

          echo ".env file created."

      - name: Create the dataset
        run: |
          echo 'Creating a raw dataset using the Kaggle API ...'
          python src/create_dataset.py
          
      # Force DVC repro to re-run all of the existing steps
      - name: Run the full DVC pipeline
        run: |
          echo "Starting the DVC pipeline ..."
          dvc repro -f