name: MLFlow Test

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  test_mlflow_secrets:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.8'

      - name: Install MLFlow
        run: |
          pip install mlflow
          pip install dagshub

      - name: Print environment variables (for debugging)
        run: |
          echo "MLFLOW_TRACKING_URI=${{ secrets.MLFLOW_TRACKING_URI }}"
          echo "DAGSHUB_USER_NAME=${{ secrets.DAGSHUB_USER_NAME }}"
          echo "DAGSHUB_PASSWORD=${{ secrets.DAGSHUB_PASSWORD }}"

      - name: Test MLFlow connection
        run: |
          python -c "
          import mlflow
          import os

          mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI'))
          mlflow.log_param('test_param', 'value')

          # Try to log something to ensure the connection is working
          print('MLFlow tracking URI set successfully')
          "


          # name: CI/CD

# on:
#   push:
#     branches:
#       - main  # Trigger the workflow on push to the main branch
#   workflow_dispatch:  # Allow manual trigger from GitHub Actions UI

# jobs:
#   Create_Run_Deploy:
#     runs-on: ubuntu-latest  # Use the latest Ubuntu runner for the workflow

#     steps:
#       # Checkout the code from GitHub repository
#       - name: Checkout code
#         uses: actions/checkout@v2  # Pulls the code from the repository

#       # Set up Python environment
#       - name: Set up Python
#         uses: actions/setup-python@v2  # Sets up Python for the workflow
#         with:
#           python-version: '3.9'  # Specifies the Python version to use

#       # Install dependencies from requirements.txt
#       - name: Install dependencies
#         run: |
#           echo "Installing libraries ..."  
#           pip install -r requirements.txt  

#       - name: Create .env file dynamically
#         run: |
#           echo "Creating .env file..."

#           echo "DAGSHUB_PASSWORD=${{ secrets.DAGSHUB_PASSWORD }}" >> .env
#           echo "DAGSHUB_USER_NAME=${{ secrets.DAGSHUB_USER_NAME }}" >> .env
#           echo "EVIDENTLY_PROJECT_ID=${{ secrets.EVIDENTLY_PROJECT_ID }}" >> .env
#           echo "EVIDENTLY_TOKEN=${{ secrets.EVIDENTLY_TOKEN }}" >> .env
#           echo "KAGGLE_KEY=${{ secrets.KAGGLE_KEY }}" >> .env
#           echo "KAGGLE_USERNAME=${{ secrets.KAGGLE_USERNAME }}" >> .env
#           echo "MLFLOW_TRACKING_URI=${{ secrets.MLFLOW_TRACKING_URI }}" >> .env
#           echo "HF_GITHUB_ACTIONS_TOKEN=${{ secrets.HF_GITHUB_ACTIONS_TOKEN }}" >> .env

#           echo ".env file created."

#       - name: Create the dataset
#         run: |
#           echo 'Creating a raw dataset using the Kaggle API ...'
#           python src/create_dataset.py
          
#       # Force DVC repro to re-run all of the existing steps
#       - name: Run the full DVC pipeline
#         run: |
#           echo 'Starting the DVC pipeline ...'
#           dvc repro -f

#       # Install jq (for parsing JSON)
#       - name: Install jq
#         run: sudo apt-get install -y jq

#       # Read Accuracy from JSON and set as environment variable
#       - name: Read Accuracy from JSON
#         id: read_accuracy
#         run: |
#           # Read the Accuracy value from current_accuracy_dict.json
#           accuracy=$(jq '.Accuracy' current_accuracy_dict.json)
#           echo "Accuracy value: $accuracy"
#           # Set the Accuracy value as an environment variable
#           echo "ACCURACY=$accuracy" >> $GITHUB_ENV

#       # Conditionally run Python scripts if Accuracy is below 0.98
#       - name: Run training and evaluation if Accuracy < 0.98
#         if: ${{ env.ACCURACY < 0.98 }}
#         run: |
#           echo "Accuracy is below 0.98. Running training and evaluation scripts..."
#           python src/integration.py
#           python src/train.py
#           python src/evaluate.py