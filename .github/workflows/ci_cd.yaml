name: CI/CD

on:
  push:
    branches:
      - main  # Trigger the workflow on push to the main branch
  workflow_dispatch:  # Allow manual trigger from GitHub Actions UI

jobs:
  Pull_and_Run:
    runs-on: ubuntu-latest  # Use the latest Ubuntu runner for the workflow

    steps:
      # Checkout the code from GitHub repository
      - name: Checkout code
        uses: actions/checkout@v2  # Pulls the code from the repository

      # Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v2  # Sets up Python for the workflow
        with:
          python-version: '3.9'  # Specifies the Python version to use

      # Install dependencies from requirements.txt
      - name: Install dependencies
        run: |
          echo "Installing libraries ..."  
          pip install -r requirements.txt  

      # # Check the DVC authentication (DagsHub) and pull the data/data_raw.csv file 
      # - name: Pull the raw data file from DagsHub (if any)
      #   run: |
      #     set -e

      #     echo 'Checking remote DVC (DagsHub) connection ...'
      #     if ! (dvc remote list | grep .); then
      #       echo 'DVC remote list failed or no remotes found, checking config...' 
      #       exit 1 
      #     else
      #       echo 'Connection verified ...'
      #     fi

      #     dvc status | grep -i "missing" | awk '{print $1}'

      #     echo 'Attempting to pull raw data from DVC ...'
      #     if ! (dvc pull -v data/raw_data.csv); then
      #       echo 'No raw data file found on DagsHub. No worries, the data will be downloaded from the Kaggle API.' 
      #     else
      #       echo 'The raw data was successfully pulled from the remote DagsHub repository.' 
      #     fi

      # (Re)create local .env file looping over secrets
      - name: Create .env file dynamically
        run: |
          echo "Creating .env file..."
          
          echo "DAGSHUB_PASSWORD=${{ secrets.DAGSHUB_PASSWORD }}" >> .env
          echo "DAGSHUB_USER_NAME=${{ secrets.DAGSHUB_USER_NAME }}" >> .env
          echo "EVIDENTLY_PROJECT_ID=${{ secrets.EVIDENTLY_PROJECT_ID }}" >> .env
          echo "EVIDENTLY_TOKEN=${{ secrets.EVIDENTLY_TOKEN }}" >> .env
          echo "KAGGLE_KEY=${{ secrets.KAGGLE_KEY }}" >> .env
          echo "KAGGLE_USERNAME=${{ secrets.KAGGLE_USERNAME }}" >> .env
          echo "MLFLOW_TRACKING_URI=${{ secrets.MLFLOW_TRACKING_URI }}" >> .env

          echo ".env file created."

      # Force DVC repro to re-run all of the existing steps
      - name: Run the full DVC pipeline
        run: |
          echo "Starting the DVC pipeline ..."
          dvc repro -f



# echo 'Setting the remote DVC (DagsHub) credentials ...'
# if ! (dvc remote add origin s3://dvc &&
#       dvc remote modify origin endpointurl https://dagshub.com/skuperst/Full-MLOps-Pipeline.s3 &&
#       dvc remote modify -v origin --local access_key_id ${{ secrets.DAGSHUB_USER_NAME }} &&
#       dvc remote modify -v origin --local secret_access_key ${{ secrets.DAGSHUB_PASSWORD }}); then
#   echo 'DagsHub identification failed! Exiting...' 
#   exit 1 
# fi
